{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4m9KmBSY9UF9kRJFgt1Vk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexlinapp/proofLLM/blob/main/finetuning_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8PNBof0eJDU",
        "outputId": "1f9ee78a-b39d-4623-f87d-4877d5afe0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, nothing should download from this.\n",
            "Data file already exists at sms_spam_collection/SMSSpamCollection.tsv. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "print(\"Hello, nothing should download from this.\")\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "  if data_file_path.exists():\n",
        "    print(f\"Data file already exists at {data_file_path}. Skipping download and extraction.\")\n",
        "    return\n",
        "\n",
        "  # downloads the file\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    with open(zip_path, \"wb\") as zip_file:\n",
        "      zip_file.write(response.read())\n",
        "\n",
        "  # unzips the file\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "  original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "  os.rename(original_file_path, data_file_path)\n",
        "  print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgk9rI5vq6Rt",
        "outputId": "c868fcc3-0574-4974-f1c8-4b15e20644de"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
        "df\n",
        "print(df[\"label\"].value_counts())\n",
        "\n",
        "\n",
        "def create_balanced_dataset(df):\n",
        "  num_spam = df[df[\"label\"] == \"spam\"].shape[0]\n",
        "  ham_subset = df[df[\"label\"] == \"ham\"].sample(n=num_spam, random_state=123)\n",
        "  balanced_df = pd.concat([ham_subset, df[df[\"label\"] == \"spam\"]])\n",
        "  return balanced_df\n",
        "\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "  train_end = int(train_frac * len(df))\n",
        "  validation_end = train_end + int(validation_frac * len(df))\n",
        "\n",
        "\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"label\"].value_counts())\n",
        "\n",
        "balanced_df[\"label\"] = balanced_df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "\n",
        "train_df.to_csv(\"train.tsv\", index=None)\n",
        "validation_df.to_csv(\"validation.tsv\", index=None)\n",
        "test_df.to_csv(\"test.tsv\", index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ypg2cYJi7Xo",
        "outputId": "0fd295c9-3bf8-48a2-b7a6-6be9dfa01356"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data['text']]\n",
        "    if max_length is None:\n",
        "      self.max_length = self.__longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "\n",
        "    self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    encoded = self.encoded_texts[idx]\n",
        "    label = self.data.iloc[idx][\"label\"]\n",
        "    return (torch.tensor(encoded), torch.tensor(label))\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __longest_encoded_length(self):\n",
        "    max_length = 0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      max_length = max(max_length, len(encoded_text))\n",
        "    return max_length"
      ],
      "metadata": {
        "id": "QoZsJNEukt67"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= SpamDataset(csv_file=\"train.tsv\", tokenizer=tokenizer)\n",
        "print(train_dataset.max_length)\n",
        "validation_dataset = SpamDataset(\"validation.tsv\", tokenizer, max_length=train_dataset.max_length)\n",
        "print(validation_dataset.max_length)\n",
        "test_dataset = SpamDataset(\"test.tsv\", tokenizer, max_length=train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbQu_lzoqubQ",
        "outputId": "8339bc67-f8fc-4f37-e138-9f9b44613cff"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8;\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "\n",
        "x = next(iter(train_loader))\n",
        "next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape\n",
        "\n",
        "\n",
        "print(f\"len(train_loader): {len(train_loader)}\")\n",
        "print(f\"len(validation_loader): {len(validation_loader)}\")\n",
        "print(f\"len(test_loader): {len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC84ghdztZR1",
        "outputId": "10f4aa9f-cb04-4d77-d8c8-fb6caa225229"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_loader): 130\n",
            "len(validation_loader): 19\n",
            "len(test_loader): 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "        \"vocab_size\" : 50257,\n",
        "        \"context_length\" : 1024,\n",
        "        \"drop_rate\" : 0.0,\n",
        "        \"qkv_bias\"  : True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "lDlI0rd_xTCK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u-7Zzq4YxmOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}